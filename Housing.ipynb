{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Housing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitakshra/Hello-world/blob/master/Housing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ibZ3BvQgstv3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import io\n",
        "from google.colab import files\n",
        "import math\n",
        "#import Multi_linear.ipynb as mp\n",
        "from sklearn.preprocessing import Imputer\n",
        "\n",
        "def correlation(x):\n",
        "  x_data = []\n",
        "  y_data = []\n",
        "  ir = []\n",
        "  li = []\n",
        "  for row  in x:\n",
        "    x_data.append(row[0:len(row)-1])\n",
        "    y_data.append(row[-1])\n",
        "    x= x_data\n",
        "    y = y_data\n",
        "  #print(len(x_data),len(x_data[0]))\n",
        "  #print(y_data)\n",
        "  for i in range(len(x_data[0])):\n",
        "    x_test = []\n",
        "    for j in range(len(x_data)):\n",
        "      x_test.append(x_data[j][i])\n",
        "    ir.append([correlate(x_test,y_data),i])\n",
        "  li = ir.sort(reverse = True)\n",
        "  return (ir)\n",
        "def correlate(x,y):\n",
        "  sum_of_x = 0\n",
        "  sum_of_y = 0\n",
        "  \n",
        "  sum_of_xsq = 0\n",
        "  #sum_of_xsq = 0\n",
        "  sum_of_ysq = 0\n",
        "  sum_of_xy = 0\n",
        "  N = len(x)\n",
        "  for i in range(len(x)):\n",
        "    sum_of_x += x[i]\n",
        "    sum_of_y += y[i]\n",
        "    sum_of_xsq += np.power(x[i],2)\n",
        "    sum_of_ysq += np.power(y[i],2)\n",
        "    sum_of_xy += x[i]*y[i]\n",
        "  num1 = N*sum_of_xy\n",
        "  num2 = sum_of_x*sum_of_y\n",
        "  num = num1-num2\n",
        "  deno1 = (N*sum_of_xsq)-(sum_of_x*sum_of_x)\n",
        "  deno2 = (N*sum_of_ysq)-(sum_of_y*sum_of_y)\n",
        "  denom = deno1*deno2\n",
        "  r = num/math.sqrt(denom)\n",
        "  return r\n",
        "  #print(r)\n",
        "def view_data(df):\n",
        "  df.hist(bins = 50,figsize=(20,15))\n",
        "  plt.show\n",
        "\n",
        "def normalize_data(x):\n",
        "  #print(len(x[0]))\n",
        "  final = []\n",
        "  for i in range(len(x[0])):\n",
        "    l = []\n",
        "    m = []\n",
        "    for j in range(len(x)):\n",
        "      l.append(x[j][i])\n",
        "    max_elt = max(l)\n",
        "    min_elt = min(l)\n",
        "    #print(\"minimum = \",min_elt,\"maximum = \",max_elt)\n",
        "    for k in range(len(x)):\n",
        "      value = (x[k][i]-min_elt)/(max_elt-min_elt)\n",
        "      m.append(value)\n",
        "    final.append(m)\n",
        "  \n",
        "    \n",
        "  return (np.array(final).T).tolist()\n",
        "  #print((np.array(final).T).tolist())\n",
        "      \n",
        "def get_y(t_data):\n",
        "  y_label = []\n",
        "  for i in t_data:\n",
        "    y_label.append(i[-1])\n",
        "  return y_label\n",
        "    \n",
        "    \n",
        "  \n",
        "\n",
        "  \n",
        "def train_test(rows,ratio):\n",
        "  shuffled_indices = np.random.permutation(len(rows))\n",
        "  #print(\"shuffled_indices\",shuffled_indices)\n",
        "  test_size = int(len(rows)*ratio)\n",
        "  test_index = shuffled_indices[:test_size]\n",
        "  train_index = shuffled_indices[test_size:]\n",
        " #@print(\"test=\",test_index,\"train = \",train_index)\n",
        "  return rows.iloc[test_index],rows.iloc[train_index]\n",
        "\n",
        "\n",
        "\n",
        "def error_data(x_array,y_array,w): #in x we send values wth the best coreleation here we choose 3 features\n",
        "  print(x_array.shape,y_array.shape,w.shape)\n",
        "  predicted_value = np.dot(x_array,w)\n",
        "  errorr = 0\n",
        "  m = len(x_array)\n",
        "  \n",
        "  for i in  range(len(x_array)):\n",
        "    errorr +=math.pow(y_array[i]-predicted_value[i],2)\n",
        "  total_error =1/m*(math.sqrt(errorr))\n",
        "  \n",
        "  return total_error\n",
        "  \n",
        "def choose_best(cor,t_data):\n",
        "  core = []\n",
        "  for row in cor[0:3]:\n",
        "    core.append(row[1])\n",
        "  df = pd.DataFrame(t_data)#converting list to data frame\n",
        "  lis = df.iloc[:,[core[0],core[1],core[2]]] #selecting best features for regression with max corelation\n",
        "  #print(lis)\n",
        "  return lis\n",
        "def predict_price(x,theta):# to compute dot product\n",
        "  return np.dot(x,theta)\n",
        "\n",
        "\n",
        "def compute_cost(alpha,x_array,y_array,w):\n",
        "  product = predict_price(x_array,w.T)\n",
        "  differnce = y_array - product\n",
        "  cost = np.dot(x_array.T,differnce.T)\n",
        "  w = w +((1/(len(x_array)))*(0.1*cost)).T\n",
        "  e = error_data(x_array,y_array,w)\n",
        "  print(\"weightr\",w)\n",
        "  print(\"error\",e)\n",
        "  return w\n",
        "  \n",
        "def gradient_descent(alpha,iterat,xdata,ydata):#to compute theta values theta 0,1,2\n",
        "  theta = np.zeros(4)\n",
        "  # adding extra one in the x data to match the bias value\n",
        "  x_array = np.array(xdata)\n",
        "  for row in xdata:\n",
        "    row.insert(0,1)\n",
        "  #print(\"after adding\",xdata)\n",
        "  x_array = np.array(xdata)\n",
        "  y_array = np.array(ydata)\n",
        "  print(\"shape of x_array\",x_array.shape)\n",
        "  for i in range(100):\n",
        "    theta = compute_cost(alpha,x_array,y_array,theta)\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "if __name__ == '__main__':\n",
        "  uploaded  = files.upload()\n",
        "  df = pd.read_csv(io.StringIO(uploaded['housing1.csv'].decode('utf-8')))\n",
        "  training_data= df.values.tolist()\n",
        "  imputer  = Imputer(strategy = \"median\")\n",
        "  # data without ocean proximity a categorical atribute\n",
        "  housing_num = df.drop(\"ocean_proximity\",axis = 1)\n",
        "   \n",
        "  \n",
        "  \n",
        "  \n",
        "  t_data = []\n",
        "  y_label = []\n",
        "  \n",
        "  #print(training_data)\n",
        "  #print(df.head())\n",
        "  #print(df.describe())\n",
        "  #df.info()\n",
        "  \n",
        "  #view_data(df)\n",
        "  \n",
        "  #correlation(training_data)\n",
        "  # splitting test data and train data\n",
        "  \n",
        "  test_data,train_data = train_test(df,0.25)\n",
        "  #droping string attribute \"ocean proximity\"\n",
        "  new_test = test_data.drop(['ocean_proximity'],axis = 1)\n",
        "  new_train = train_data.drop(['ocean_proximity'],axis = 1)\n",
        "  \n",
        "  \n",
        "  # data cleaning missing value by \n",
        "  new_test['total_bedrooms'].fillna(558,inplace = True)\n",
        "  new_train['total_bedrooms'].fillna(558,inplace = True)\n",
        "  #print(\"improved\",new_test.isnull().sum(),\"train\",new_train.isnull().sum())\n",
        "  test_list = new_test.values.tolist()\n",
        "  train_list = new_train.values.tolist()\n",
        "  n_test = normalize_data(test_list)\n",
        "  n_train = normalize_data(train_list)\n",
        "  \n",
        "  #print(\"dimesion\",(np.array(n_test).shape))\n",
        "  cor = correlation(n_train)\n",
        "  #print(\"coorelation\",cor)\n",
        "  lis_df = choose_best(cor,n_train)#choosing best three values\n",
        "  print(\"head\",lis_df.head())\n",
        "  x_train = lis_df.values.tolist()\n",
        "  y_train = get_y(n_train)\n",
        "  #print(\"y label\",y_train)\n",
        "  #print(\"X values\",x_train)\n",
        "  gradient_descent(0.00025,10,x_train,y_train)\n",
        "  \n",
        "  \n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}